{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHXiEHrtVVxl"
      },
      "source": [
        "# Super Wav2Lip\n",
        "\n",
        "This Colab project is based on [Wav2Lip-GFPGAN](https://github.com/ajay-sainy/Wav2Lip-GFPGAN), but updates the requirements.txt (to function properly) and updates Colab file for ease of use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhFe3CJGAIiV"
      },
      "outputs": [],
      "source": [
        "#@title <h1>Step1: Setup Wav2Lip</h1>\n",
        "#@markdown * Install dependency\n",
        "#@markdown * Download pretrained model\n",
        "\n",
        "!git clone https://github.com/indianajson/wav2lip-HD.git\n",
        "basePath = \"/content/wav2lip-HD\"\n",
        "%cd {basePath}\n",
        "\n",
        "wav2lipFolderName = 'Wav2Lip-master'\n",
        "gfpganFolderName = 'GFPGAN-master'\n",
        "wav2lipPath = basePath + '/' + wav2lipFolderName\n",
        "gfpganPath = basePath + '/' + gfpganFolderName\n",
        "\n",
        "!wget 'https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth' -O {wav2lipPath}'/face_detection/detection/sfd/s3fd.pth'\n",
        "\n",
        "!wget 'https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA' -O {wav2lipPath}'/checkpoints/wav2lip_gan.pth'\n",
        "#!wget 'https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/Eb3LEzbfuKlJiR600lQWRxgBIY27JZg80f7V9jtMfbNDaQ?e=TBFBVW' -O {wav2lipPath}'/checkpoints/wav2lip.pth'\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1fQtBSYEyuai9MjBOF8j7zZ4oQ9W2N64q --output {wav2lipPath}'/checkpoints/'\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "!pip install -U librosa==0.8.1 # The process will fail without downgrading librosa\n",
        "!mkdir inputs\n",
        "\n",
        "!cd $gfpganFolderName && python setup.py develop\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P {gfpganFolderName}'/experiments/pretrained_models'\n",
        "\n",
        "%cd {basePath}\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "print(\"Installation complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. LipSync on Your Video File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from IPython.display import HTML, clear_output\n",
        "from base64 import b64encode\n",
        "import moviepy.editor as mp\n",
        "\n",
        "\n",
        "def showVideo(file_path):\n",
        "    \"\"\"Function to display video in Colab\"\"\"\n",
        "    mp4 = open(file_path,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    display(HTML(\"\"\"\n",
        "    <video controls width=600>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\" % data_url))\n",
        "\n",
        "def get_video_resolution(video_path):\n",
        "    \"\"\"Function to get the resolution of a video\"\"\"\n",
        "    import cv2\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    return (width, height)\n",
        "\n",
        "def resize_video(video_path, new_resolution):\n",
        "    \"\"\"Function to resize a video\"\"\"\n",
        "    import cv2\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    fourcc = int(video.get(cv2.CAP_PROP_FOURCC))\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "    width, height = new_resolution\n",
        "    output_path = os.path.splitext(video_path)[0] + '_720p.mp4'\n",
        "    writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "    while True:\n",
        "        success, frame = video.read()\n",
        "        if not success:\n",
        "            break\n",
        "        resized_frame = cv2.resize(frame, new_resolution)\n",
        "        writer.write(resized_frame)\n",
        "    video.release()\n",
        "    writer.release()\n",
        "\n",
        "#@markdown ### Select an uploading method\n",
        "upload_method = \"Upload\" #@param [\"Upload\", \"Custom Path\"]\n",
        "inputVideo = 'vid.mp4' #@param{type:\"string\"}\n",
        "\n",
        "\n",
        "# remove previous input video\n",
        "if os.path.isfile(basePath + '/inputs/'+ inputVideo):\n",
        "    os.remove(basePath + '/inputs/'+ inputVideo)\n",
        "\n",
        "if upload_method == \"Upload\":\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        os.rename(filename, basePath + '/inputs/'+ inputVideo)\n",
        "    PATH_TO_YOUR_VIDEO = basePath + '/inputs/'+ inputVideo\n",
        "\n",
        "elif upload_method == 'Custom Path':\n",
        "    # Mount Google Drive if it's not already mounted\n",
        "    #if not os.path.isdir(\"/content/drive/MyDrive\"):\n",
        "    #    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    #@markdown ``Add the full path to your video on your Gdrive `` ðŸ‘‡\n",
        "    PATH_TO_YOUR_VIDEO = '/content/drive/MyDrive/test.mp4' #@param {type:\"string\"}\n",
        "    if not os.path.isfile(PATH_TO_YOUR_VIDEO):\n",
        "        print(\"ERROR: File not found!\")\n",
        "        raise SystemExit(0)\n",
        "\n",
        "#@markdown <font color=\"orange\">Notes:\n",
        "\n",
        "#@markdown <font color=\"orange\">. ``If your uploaded video is 1080p or higher resolution, this cell will resize it to 720p.``\n",
        "\n",
        "#@markdown <font color=\"orange\">. ``Do not upload videos longer than 60 seconds.``\n",
        "\n",
        "#@markdown ___\n",
        "\n",
        "video_duration = mp.VideoFileClip(PATH_TO_YOUR_VIDEO).duration\n",
        "if video_duration > 60:\n",
        "    print(\"WARNING: Video duration exceeds 60 seconds. Please upload a shorter video.\")\n",
        "    raise SystemExit(0)\n",
        "\n",
        "video_resolution = get_video_resolution(PATH_TO_YOUR_VIDEO)\n",
        "print(f\"Video resolution: {video_resolution}\")\n",
        "if video_resolution[0] >= 1920 or video_resolution[1] >= 1080:\n",
        "    print(\"Resizing video to 720p...\")\n",
        "    os.system(f\"ffmpeg -i {PATH_TO_YOUR_VIDEO} -vf scale=1280:720 basePath + '/inputs/'+ inputVideo\")\n",
        "    PATH_TO_YOUR_VIDEO = basePath + '/inputs/'+ inputVideo\n",
        "    print(\"Video resized to 720p\")\n",
        "else:\n",
        "    print(\"No resizing needed\")\n",
        "\n",
        "if upload_method == \"Upload\":\n",
        "  clear_output()\n",
        "  print(\"Input Video\")\n",
        "  showVideo(PATH_TO_YOUR_VIDEO)\n",
        "else:\n",
        "    if os.path.isfile(PATH_TO_YOUR_VIDEO):\n",
        "        shutil.copyfile(PATH_TO_YOUR_VIDEO, basePath + '/inputs/'+ inputVideo)\n",
        "        print(\"Input Video\")\n",
        "        showVideo(PATH_TO_YOUR_VIDEO)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title STEP3: Select Audio (Record, Upload from local drive or Gdrive)\n",
        "import os\n",
        "from IPython.display import Audio\n",
        "from IPython.core.display import display\n",
        "\n",
        "upload_method = 'Upload' #@param ['Record', 'Upload']\n",
        "inputAudio = 'audio.mp3' #@param{type:\"string\"}\n",
        "\n",
        "\n",
        "# remove previous input audio\n",
        "if os.path.isfile(basePath + '/inputs/'+ inputAudio):\n",
        "    os.remove(basePath + '/inputs/'+ inputAudio)\n",
        "\n",
        "\n",
        "def displayAudio():\n",
        "  display(Audio(basePath + '/inputs/'+ inputAudio))\n",
        "\n",
        "if upload_method == 'Record':\n",
        "  audio, sr = get_audio()\n",
        "  import scipy\n",
        "  scipy.io.wavfile.write(basePath + '/inputs/'+ inputAudio, sr, audio)\n",
        "\n",
        "elif upload_method == 'Upload':\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes.'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "  # Consider only the first file\n",
        "  PATH_TO_YOUR_AUDIO = str(list(uploaded.keys())[0])\n",
        "\n",
        "  # Load audio with specified sampling rate\n",
        "  import librosa\n",
        "  audio, sr = librosa.load(PATH_TO_YOUR_AUDIO, sr=None)\n",
        "\n",
        "  # Save audio with specified sampling rate\n",
        "  import soundfile as sf\n",
        "  file_format = 'mp3' #@param{type:\"string\"}\n",
        "  #file_format = 'wav' #@param ['wav', 'mp3', 'ogg']\n",
        "  sf.write(basePath + '/inputs/'+ inputAudio, audio, sr, format=file_format)\n",
        "\n",
        "  clear_output()\n",
        "  displayAudio()\n",
        "\n",
        "else: # Custom Path\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  #@markdown ``Add the full path to your audio on your Gdrive`` ðŸ‘‡\n",
        "  PATH_TO_YOUR_AUDIO = '/content/drive/MyDrive/test.wav' #@param {type:\"string\"}\n",
        "\n",
        "  # Load audio with specified sampling rate\n",
        "  import librosa\n",
        "  audio, sr = librosa.load(PATH_TO_YOUR_AUDIO, sr=None)\n",
        "\n",
        "  # Save audio with specified sampling rate\n",
        "  import soundfile as sf\n",
        "  sf.write('/content/sample_data/input_audio.wav', audio, sr, format='wav')\n",
        "\n",
        "  clear_output()\n",
        "  displayAudio()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0BMWoIyX2dc"
      },
      "source": [
        "## 4. Synchronize Video and Speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EqX_2YtkUjRI"
      },
      "outputs": [],
      "source": [
        "#@markdown Adjust the parameters below then run the code block to synthesize the speech onto your video file:\n",
        "\n",
        "import os\n",
        "outputPath = basePath + '/outputs' \n",
        "inputAudio = 'audio.mp3' #@param{type:\"string\"}\n",
        "inputAudioPath = basePath + '/inputs/' + inputAudio  \n",
        "inputVideo = 'video.mov' #@param{type:\"string\"}\n",
        "inputVideoPath = basePath + '/inputs/'+ inputVideo\n",
        "lipSyncedOutputPath = basePath + '/outputs/result.mp4'  \n",
        "model = \"wav2lip\" #@param [\"wav2lip\", \"wav2lip_gan\"] {type:\"string\"}\n",
        "\n",
        "\n",
        "if not os.path.exists(outputPath):\n",
        "  os.makedirs(outputPath)\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "!cd $wav2lipFolderName && python inference.py \\\n",
        "--checkpoint_path checkpoints/{model}.pth \\\n",
        "--face {inputVideoPath} \\\n",
        "--audio {inputAudioPath} \\\n",
        "--outfile {lipSyncedOutputPath}\n",
        "\n",
        "\n",
        "\n",
        "#print(\"Video synthesis complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAIIanxYqFcE"
      },
      "source": [
        "## 3. Boost the Resolution of the Synthesized Video\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XibzGPIVJfvP"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from os import path\n",
        "\n",
        "import os\n",
        "\n",
        "inputVideoPath = outputPath+'/result.mp4'\n",
        "unProcessedFramesFolderPath = outputPath+'/frames'\n",
        "\n",
        "if not os.path.exists(unProcessedFramesFolderPath):\n",
        "  os.makedirs(unProcessedFramesFolderPath)\n",
        "\n",
        "vidcap = cv2.VideoCapture(inputVideoPath)\n",
        "numberOfFrames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
        "print(\"FPS: \", fps, \"Frames: \", numberOfFrames)\n",
        "\n",
        "for frameNumber in tqdm(range(numberOfFrames)):\n",
        "    _,image = vidcap.read()\n",
        "    cv2.imwrite(path.join(unProcessedFramesFolderPath, str(frameNumber).zfill(4)+'.jpg'), image)\n",
        "\n",
        "\n",
        "!cd $gfpganFolderName && \\\n",
        "  python inference_gfpgan.py -i $unProcessedFramesFolderPath -o $outputPath -v 1.3 -s 2 --only_center_face --bg_upsampler None\n",
        "\n",
        "import os\n",
        "restoredFramesPath = outputPath + '/restored_imgs/'\n",
        "processedVideoOutputPath = outputPath\n",
        "\n",
        "dir_list = os.listdir(restoredFramesPath)\n",
        "dir_list.sort()\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#Get FPS of original video for writer\n",
        "inputVideoPath = outputPath+'/result.mp4'\n",
        "vidcap = cv2.VideoCapture(inputVideoPath)\n",
        "fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
        "print(\"The video is \"+str(fps)+\" FPS.\")\n",
        "\n",
        "batch = 0\n",
        "batchSize = 1300\n",
        "from tqdm import tqdm\n",
        "for i in tqdm(range(0, len(dir_list), batchSize)):\n",
        "  img_array = []\n",
        "  start, end = i, i+batchSize\n",
        "  print(\"processing \", start, end, end=\"\\r\")\n",
        "  for filename in  tqdm(dir_list[start:end]):\n",
        "      filename = restoredFramesPath+filename;\n",
        "      img = cv2.imread(filename)\n",
        "      if img is None:\n",
        "        continue\n",
        "      height, width, layers = img.shape\n",
        "      size = (width,height)\n",
        "      img_array.append(img)\n",
        "  out = cv2.VideoWriter(processedVideoOutputPath+'/output_'+str(batch).zfill(4)+'.mp4',cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
        "  batch = batch + 1\n",
        " \n",
        "  for i in range(len(img_array)):\n",
        "    out.write(img_array[i])\n",
        "  out.release()\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "print(\"Video upscaling complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title STEP4: Download \n",
        "from google.colab import files\n",
        "#@markdown ``Path to file `` ðŸ‘‡\n",
        "inputFile= '/outputs/' #@param {type:\"string\"}\n",
        "PATH_TO_YOUR_File = basePath + inputFile\n",
        "\n",
        "    if not os.path.isfile(PATH_TO_YOUR_File):\n",
        "        print(\"ERROR: File not found!\")\n",
        "        raise SystemExit(0)\n",
        "\n",
        "    else:\n",
        "        files.download(PATH_TO_YOUR_File)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajuOpF9t0psE"
      },
      "source": [
        "## 5. Clear Cached Files\n",
        "\n",
        "Run this block once you've downloaded your final video file. This will empty /inputs and /outputs, so you can start again, fresh.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8JhzA9t_xrS"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "o2trJyiC0mRs"
      },
      "outputs": [],
      "source": [
        "%cd /content/wav2lip-HD/\n",
        "\n",
        "#@markdown Choose whether to remove both inputs and outputs, or just one of the two. You may want to preserve inputs if you are only changing one of the two inputs. \n",
        "\n",
        "removeInputs = True #@param {type:\"boolean\"}\n",
        "removeOutputs = True #@param {type:\"boolean\"}\n",
        "\n",
        "if removeInputs == True:\n",
        "  %rm inputs/*\n",
        "if removeOutputs == True:\n",
        "  %rm outputs/frames/*\n",
        "  %rm outputs/restored_imgs/*\n",
        "  %rm outputs/*\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "print(\"Cleared cached files.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
